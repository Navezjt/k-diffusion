{
  "configurations": [
    {
      "name": "Python: Oxford Flowers (shifted window)",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "subProcess": false,
      "args": [
        "--config", "configs/config_oxford_flowers_shifted_window.json",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
        "--start-method", "fork",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    {
      "name": "Python: Oxford Flowers (NATTEN)",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "subProcess": false,
      "args": [
        "--config", "configs/config_oxford_flowers.json",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
        "--start-method", "fork",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    {
      "name": "Python: Oxford Flowers class-conditional (NATTEN)",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config", "configs/config_oxford_flowers_classcond.json",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
        "--start-method", "fork",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    {
      "name": "Python: Oxford Flowers class-conditional latent (NATTEN)",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config", "configs/config_oxford_flowers_classcond_latent.juelich.jsonc",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_latent_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
        "--start-method", "fork",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    // /home/mahouko/.cache/huggingface/accelerate/default_config.yaml
    {
      "name": "Python: Oxford Flowers (shifted window) [accelerate]",
      "type": "python",
      "request": "launch",
      "module": "accelerate.commands.launch",
      "console": "integratedTerminal",
      "justMyCode": true,
      "subProcess": false,
      "args": [
        "--config_file", "/home/mahouko/.cache/huggingface/accelerate/fsdp_kat_shifted.yaml",
        "train.py",
        "--config", "configs/config_oxford_flowers_shifted_window.json",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--start-method", "fork",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    {
      "name": "Python: Oxford Flowers (NATTEN) [accelerate]",
      "type": "python",
      "request": "launch",
      "module": "accelerate.commands.launch",
      "console": "integratedTerminal",
      "justMyCode": true,
      "subProcess": false,
      "args": [
        "--config_file", "/home/mahouko/.cache/huggingface/accelerate/fsdp_kat.yaml",
        "train.py",
        "--config", "configs/config_oxford_flowers.json",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--text-model-trust-remote-code",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    {
      "name": "Python: Oxford Flowers Cross-attn (NATTEN)",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "subProcess": false,
      "args": [
        "--config", "configs/config_oxford_flowers_crossattn.jsonc",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_xattn_001",
        "--evaluate-n", "0",
        "--batch-size", "32",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--start-method", "fork",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--text-model-trust-remote-code",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
        "TOKENIZERS_PARALLELISM": "false",
      }
    },
    {
      "name": "Python: Oxford Flowers Cross-attn (NATTEN) [accelerate]",
      "type": "python",
      "request": "launch",
      "module": "accelerate.commands.launch",
      "console": "integratedTerminal",
      "justMyCode": true,
      "subProcess": false,
      "args": [
        "--config_file", "/p/project/ccstdl/birch1/.cache/huggingface/accelerate/ddp.yaml",
        "train.py",
        "--config", "configs/config_oxford_flowers_crossattn.jsonc",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "flowers_demo_xattn_accelerate_001",
        "--demo-title-qualifier", "DDP",
        "--evaluate-n", "0",
        "--batch-size", "128",
        "--sample-n", "36",
        "--mixed-precision", "bf16",
        "--start-method", "fork",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--text-model-trust-remote-code",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
      ],
      "env": {
        // "K_DIFFUSION_USE_COMPILE": "0",
        // "TORCHINDUCTOR_COMPILE_THREADS": "1",
        "TOKENIZERS_PARALLELISM": "false",
      }
    },
    {
      "name": "Python: Compute FID OpenAI",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "args": [
        "--config", "configs/config_guided_diffusion_imagenet.jsonc",
        // "--resume-inference", "/nvme1/ml-weights/256x256_diffusion.pt",
        "--resume-inference", "/p/scratch/ccstdl/birch1/256x256_diffusion.pt",
        "--evaluate-only",
        "--evaluate-n", "4",
        "--start-method", "fork"
      ]
    },
    {
      "name": "Python: Subset WDS",
      "type": "python",
      "request": "launch",
      "program": "subset_wds.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "args": []
    },
    {
      "name": "Python: Subset WDS RGB",
      "type": "python",
      "request": "launch",
      "program": "subset_wds_rgb.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "args": []
    },
    {
      "name": "Python: Inference OpenAI",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": true,
      "args": [
        "--config", "configs/config_guided_diffusion_imagenet.jsonc",
        // "--resume-inference", "/nvme1/ml-weights/256x256_diffusion.pt",
        "--resume-inference", "/p/scratch/ccstdl/birch1/256x256_diffusion.pt",
        "--inference-only",
        "--sample-n", "16",
        "--start-method", "fork"
      ]
    },
    {
      "name": "Python: Inference many OpenAI",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "args": [
        "--config", "configs/config_guided_diffusion_imagenet.jsonc",
        // "--resume-inference", "/nvme1/ml-weights/256x256_diffusion.pt",
        "--resume-inference", "/p/scratch/ccstdl/birch1/256x256_diffusion.pt",
        "--inference-only",
        "--inference-n", "10",
        "--inference-out-wds-root", "out/wds",
        "--inference-out-wds-shard", "0",
        "--sample-n", "4",
        "--start-method", "fork"
      ],
    },
    {
      "name": "Python: Evaluate OpenAI dataset",
      "type": "python",
      "request": "launch",
      "program": "compute_metrics.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config-pred", "configs/dataset/pred/guided_diffusion.mahouko.jsonc",
        "--config-target", "configs/dataset/imagenet.mahouko.jsonc",
        "--evaluate-n", "50000",
        "--batch-size", "256",
        // "--num-workers", "1",
        "--start-method", "fork",
        "--torchmetrics-fid",
      ],
    },
    {
      "name": "Python: Evaluate 557M",
      "type": "python",
      "request": "launch",
      "program": "compute_metrics.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config-pred", "configs/dataset/pred/557M_cfg1.00.juelich.jsonc",
        "--config-target", "configs/dataset/imagenet.juelich.jsonc",
        "--evaluate-n", "50000",
        "--batch-size", "768",
        "--start-method", "fork",
        "--torchmetrics-fid",
        "--mixed-precision", "fp16",
        "--evaluate-with", "inception", "dinov2"
      ],
      "env": {
        "K_DIFFUSION_USE_COMPILE": "0"
      },
    },
    {
      // note: dataloader seems to get exhausted prematurely, so this just doesn't work
      "name": "Python: Evaluate 557M (accelerate)",
      "type": "python",
      "request": "launch",
      "module": "accelerate.commands.launch",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config_file", "/p/project/ccstdl/birch1/.cache/huggingface/accelerate/ddp.yaml",
        // "--num_processes", "2",
        "compute_metrics.py",
        "--config-pred", "configs/dataset/pred/557M_cfg1.00.juelich.jsonc",
        "--config-target", "configs/dataset/imagenet.juelich.jsonc",
        "--evaluate-n", "50000",
        "--batch-size", "768",
        // "--start-method", "fork",
        "--torchmetrics-fid",
        "--mixed-precision", "fp16",
        "--evaluate-with", "inception", "dinov2"
      ],
      "env": {
        // "CUDA_VISIBLE_DEVICES": "0,1",
        "K_DIFFUSION_USE_COMPILE": "0"
      },
    },
    {
      "name": "Python: Ablation integration-test",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config", "configs/ablations/hourglass_base.jsonc",
        "--out-root", "out",
        "--output-to-subdir",
        "--name", "ablation_hourglass_base_demo_001",
        "--sample-n", "36",
        "--demo-every", "64",
        "--evaluate-n", "16",
        "--evaluate-every", "128",
        "--save-every", "150",
        "--batch-size", "32",
        "--mixed-precision", "bf16",
        "--demo-classcond-include-uncond",
        "--demo-img-compress",
        "--font", "./kdiff_trainer/font/DejaVuSansMono.ttf",
        "--start-method", "fork",
      ],
      "env": {
        "K_DIFFUSION_USE_COMPILE": "0",
        "TORCHINDUCTOR_COMPILE_THREADS": "1",
      },
    },
    {
      "name": "Python: Inference many 557M",
      "type": "python",
      "request": "launch",
      "program": "train.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "args": [
        "--config", "configs/config_557M.jsonc",
        // "--resume-inference", "/nvme1/ml-weights/256x256_diffusion.pt",
        // "--resume-inference", "/p/scratch/ccstdl/birch1/256x256_diffusion.pt",
        "--resume-inference", "/p/scratch/ccstdl/birch1/ckpt/imagenet_test_v2_007_02200000.safetensors",
        "--inference-only",
        "--cfg-scale", "1.4",
        "--demo-title-qualifier", "CFG 1.4",
        // "--inference-n", "10",
        // "--inference-out-wds-root", "out/wds3",
        // "--inference-out-wds-shard", "0",
        "--sample-n", "64",
        "--start-method", "fork",
        "--name", "kat-557M",
        // "--goose-mode",
      ],
      "env": {
        "K_DIFFUSION_USE_COMPILE": "0",
        "TORCHINDUCTOR_COMPILE_THREADS": "1",
      }
    },
    {
      "name": "Python: Read preprocessed latent dataset",
      "type": "python",
      "request": "launch",
      "program": "read_latent_dataset.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": true,
      "args": [],
      "env": {}
    },
    {
      "name": "Python: Preprocess latent dataset",
      "type": "python",
      "request": "launch",
      "program": "imagenet_vae_loading.py",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": true,
      "args": [
        "--config", "configs/dataset/imagenet.juelich.jsonc",
        "--batch-size", "256",
        "--num-workers", "8",
        "--log-average-every-n", "25",
        "--save-average-every-n", "250",
        "--out-root", "/p/scratch/ccstdl/birch1/dataset-out/imagenet-latents",
        "--start-method", "fork",
      ],
      "env": {
        "K_DIFFUSION_USE_COMPILE": "0",
        "TORCHINDUCTOR_COMPILE_THREADS": "1",
      }
    },
    {
      "name": "Python: Preprocess latent dataset (accelerate)",
      "type": "python",
      "request": "launch",
      "module": "accelerate.commands.launch",
      "console": "integratedTerminal",
      "justMyCode": false,
      "subProcess": false,
      "args": [
        "--config_file", "/p/project/ccstdl/birch1/.cache/huggingface/accelerate/ddp.yaml",
        "imagenet_vae_loading.py",
        "--config", "configs/dataset/imagenet.juelich.jsonc",
        "--batch-size", "256",
        "--num-workers", "8",
        "--log-average-every-n", "25",
        "--save-average-every-n", "250",
        "--out-root", "/p/scratch/ccstdl/birch1/dataset-out/imagenet-latents",
        "--start-method", "fork",
      ],
      "env": {
        "K_DIFFUSION_USE_COMPILE": "0",
        "TORCHINDUCTOR_COMPILE_THREADS": "1",
        "PYDEVD_DISABLE_FILE_VALIDATION": "1",
      }
    },
  ]
}
